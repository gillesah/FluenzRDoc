---
title: A/B Testing
description: Optimisez vos campagnes en testant diff√©rentes versions de vos emails.
---

# A/B Testing

L'A/B testing vous permet de comparer diff√©rentes versions de vos emails pour identifier ce qui fonctionne le mieux.

> **‚ÑπÔ∏è Info**
L'A/B testing est disponible √† partir du plan **Starter**.

## Qu'est-ce que l'A/B Testing ?

L'A/B testing (ou split testing) consiste √† :
1. Cr√©er deux versions (A et B) d'un email
2. Envoyer chaque version √† une partie de vos contacts
3. Mesurer quelle version performe le mieux
4. Utiliser ces apprentissages pour vos futures campagnes

## Ce que vous pouvez tester

### Objets d'email

L'√©l√©ment le plus impactant sur le taux d'ouverture.

**Exemples de tests :**
| Version A | Version B |
|-----------|-----------|
| Question rapide | {{firstName}}, question rapide |
| Am√©liorer vos ventes | 3 techniques pour doubler vos ventes |
| Invitation | Vous √™tes invit√©(e) |

### Contenu de l'email

Impact sur le taux de clic et de r√©ponse.

**Exemples de tests :**
- Longueur (court vs d√©taill√©)
- Ton (formel vs conversationnel)
- Structure (paragraphes vs listes)
- CTA (call-to-action)

### Exp√©diteur

Le nom d'exp√©diteur influence l'ouverture.

| Version A | Version B |
|-----------|-----------|
| Jean Dupont | Jean de FluenzR |
| Marketing FluenzR | jean@fluenzr.co |

## Cr√©er un A/B test

### 1. Activer l'A/B test

Dans l'√©diteur de workflow :
1. Cliquez sur un n≈ìud Email
2. Activez l'option **A/B Test**
3. Une version B est automatiquement cr√©√©e

### 2. Configurer les versions

**Version A :**
- Remplissez l'objet A
- R√©digez le contenu A

**Version B :**
- Cliquez sur l'onglet "Version B"
- Remplissez l'objet B
- R√©digez le contenu B

### 3. D√©finir la r√©partition

| Param√®tre | Description | Recommandation |
|-----------|-------------|----------------|
| **R√©partition** | % de contacts pour chaque version | 50/50 |
| **Crit√®re de succ√®s** | M√©trique √† optimiser | Taux d'ouverture |

### 4. Option : Envoi automatique du gagnant

Activez cette option pour :
1. Tester sur un √©chantillon (ex: 20% des contacts)
2. Attendre les r√©sultats (ex: 24h)
3. Envoyer automatiquement la version gagnante aux 80% restants

## M√©triques de comparaison

### Taux d'ouverture

Pertinent pour tester les objets.

| Version | Envoy√©s | Ouverts | Taux |
|---------|---------|---------|------|
| A | 500 | 125 | 25% |
| B | 500 | 175 | **35%** |

‚Üí Version B gagnante (+40% d'ouvertures)

### Taux de clic

Pertinent pour tester le contenu et les CTA.

| Version | Ouverts | Clics | Taux |
|---------|---------|-------|------|
| A | 125 | 15 | 12% |
| B | 175 | 14 | 8% |

‚Üí Version A gagnante pour le taux de clic

### Taux de r√©ponse

La m√©trique ultime pour la prospection.

| Version | Envoy√©s | R√©ponses | Taux |
|---------|---------|----------|------|
| A | 500 | 8 | 1.6% |
| B | 500 | 15 | **3%** |

‚Üí Version B gagnante pour les r√©ponses

## Analyser les r√©sultats

### Signification statistique

Un r√©sultat est fiable si :
- L'√©chantillon est suffisant (>100 par version)
- La diff√©rence est significative (>10% d'√©cart)
- Le test a dur√© assez longtemps (>48h)

> **‚ö†Ô∏è Attention**
Avec de petits √©chantillons, les r√©sultats peuvent √™tre dus au hasard. Attendez d'avoir assez de donn√©es avant de conclure.

### Interpr√©tation

| √âcart | Interpr√©tation |
|-------|----------------|
| <5% | Pas de diff√©rence significative |
| 5-15% | Tendance √† confirmer |
| >15% | Diff√©rence significative |

## Bonnes pratiques

### Ne testez qu'un √©l√©ment

Pour savoir ce qui fait la diff√©rence, ne changez qu'une chose :

| ‚ùå Mauvais | ‚úÖ Bon |
|-----------|-------|
| Objet diff√©rent + Contenu diff√©rent | Seulement l'objet |
| Tout est diff√©rent | Une variable √† la fois |

### √âchantillon suffisant

| Taille liste | √âchantillon test recommand√© |
|--------------|----------------------------|
| <500 | Test sur 100% (50/50) |
| 500-2000 | Test sur 50% |
| >2000 | Test sur 20-30% |

### Dur√©e du test

Attendez assez longtemps pour avoir des r√©sultats fiables :

| Type d'email | Dur√©e minimum |
|--------------|---------------|
| Prospection | 48-72h |
| Newsletter | 24-48h |
| Urgent | 12-24h |

### Documentez vos tests

Tenez un journal de vos A/B tests :
- Hypoth√®se de d√©part
- Ce qui a √©t√© test√©
- R√©sultats chiffr√©s
- Conclusion actionnable

## Id√©es de tests

### Objets √† tester

| √âl√©ment | Exemple A | Exemple B |
|---------|-----------|-----------|
| Personnalisation | "Question" | "{{firstName}}, question" |
| Question vs Affirmation | "Comment augmenter vos ventes ?" | "Augmentez vos ventes de 30%" |
| Longueur | "Disponible cette semaine ?" | "√ätes-vous disponible pour un call de 15 min cette semaine ?" |
| √âmoji | "Question rapide" | "Question rapide üëã" |
| Urgence | "Une id√©e pour vous" | "Cette semaine uniquement" |

### Contenus √† tester

| √âl√©ment | Version A | Version B |
|---------|-----------|-----------|
| Longueur | 3 paragraphes | 1 paragraphe |
| CTA | "R√©pondez √† cet email" | "Cliquez ici pour r√©server un cr√©neau" |
| Social proof | Sans t√©moignage | Avec t√©moignage client |
| Format | Texte plein | Liste √† puces |

## FAQ

### Puis-je faire un test A/B/C ?

Non, FluenzR supporte uniquement les tests √† 2 versions. Pour tester 3 options, faites des tests successifs.

### Le test fonctionne-t-il sur les relances ?

Oui, chaque email de la s√©quence peut avoir son propre A/B test.

### Comment les contacts sont-ils r√©partis ?

Al√©atoirement. Chaque contact est assign√© √† une version au moment de l'envoi.

### Puis-je modifier un test en cours ?

Non, modifier un test en cours fausserait les r√©sultats. Cr√©ez une nouvelle campagne si n√©cessaire.
